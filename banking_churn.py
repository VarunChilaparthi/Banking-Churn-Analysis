# -*- coding: utf-8 -*-
"""Banking churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yF3Gm3ItZmd09fYuTWtiZ5DQGoNtj7tu
"""

import pandas as pd

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('Bank Customer Churn Prediction.csv')

df.head(3)

df.describe()

df.info()

df.isna().sum()

!pip install ydata-profiling

import ydata_profiling as yd

from pandas_profiling import ProfileReport

from ydata_profiling import ProfileReport
#sweetviz and ydata-profiling are called automated exploratory data analysis

profile = ProfileReport(df, title = "Report")

profile

!pip install sweetviz

import sweetviz as sv

report1 = sv.analyze(df)

df1 = df[1:10]

report2 = sv.analyze(df1)

report2.show_html('report2.html')

report2.show_notebook()

df.head()

df.drop(['customer_id'], axis = 1, inplace = True)

df.head()

df["gender"].value_counts()

df["country"].value_counts()

df["gender_en"] = df["gender"].map({"Male": 1, "Female": 0}).astype(int)

df["country_en"] = df["country"].map({"France": 0, "Germany": 1, "Spain": 2}).astype(int)

df.head(5)

cols = ["balance", "age", "estimated_salary","credit_score"]

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()

df[cols] = ss.fit_transform(df[cols])

df.head()

from sklearn.model_selection import train_test_split

Y = df["churn"]
X = df[["credit_score","age","tenure","balance","products_number","credit_card","active_member","estimated_salary","gender_en","country_en"]]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)

from sklearn.tree import DecisionTreeClassifier

ct = DecisionTreeClassifier()

ct = DecisionTreeClassifier(criterion="entropy")

ct.fit(X_train, Y_train)

y_pred = ct.predict(X_test)

y_pred

Y_test

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score

accuracy_score(Y_test, y_pred)

precision_score(Y_test, y_pred)

f1_score(Y_test, y_pred)

import pandas as pd
feature_imp = pd.Series(ct.feature_importances_, index = X.columns).sort_values(ascending = False)
feature_imp

ct.feature_importances_

X_train.columns

# Commented out IPython magic to ensure Python compatibility.
#visualizing feature importance results
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
# Creating a bar plot
sns.barplot(x=feature_imp, y=feature_imp.index)
# Add labels to your graph
plt.xlabel('Feature Importance Score')
plt.ylabel('Features')
plt.title("Visualizing Important Features")
plt.legend()
plt.show()

from sklearn import tree
fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (4,4), dpi = 300)

tree.plot_tree(ct, max_depth = 2,  # Draw upto depth of 3
            rounded = True, # Rounded boxes
            filled = True,  # Boxes filled with color
            impurity = True,# Show impurity level
            node_ids = True,# Display node_id
            feature_names = ['credit_score', 'age', 'tenure', 'balance', 'products_number','credit_card', 'active_member', 'estimated_salary', 'gender_en', 'country_en'],
            class_names = ["1","0"]
              )
#fig.savefig('C://Users//IMI KOLKATA//Desktop//plottreedefault.png')

cnt=0
for i in ['credit_score', 'age', 'tenure', 'balance', 'products_number','credit_card', 'active_member', 'estimated_salary', 'gender_en', 'country_en']:
    print("feature ",cnt,": --------------> ",i)
    cnt+=1



from sklearn.tree import export_text

tree_rules = export_text(ct, feature_names=list(X_train.columns))

print(tree_rules)

def get_rules(tree, feature_names, class_names):
    tree_ = tree.tree_
    feature_name = [
        feature_names[i] for i in tree_.feature
    ]

    paths = []
    path = []

    def recurse(node, path, paths):

        if str(tree_.feature[node]).isnumeric() == True:
            name = feature_name[node]
            threshold = tree_.threshold[node]
            p1, p2 = list(path), list(path)
            p1 += [f"({name} <= {np.round(threshold, 3)})"]
            recurse(tree_.children_left[node], p1, paths)
            p2 += [f"({name} > {np.round(threshold, 3)})"]
            recurse(tree_.children_right[node], p2, paths)
        else:
            path += [(tree_.value[node], tree_.n_node_samples[node])]
            paths += [path]

    recurse(0, path, paths)

    # sort by samples count
    samples_count = [p[-1][1] for p in paths]
    ii = list(np.argsort(samples_count))
    paths = [paths[i] for i in reversed(ii)]

    rules = []
    for path in paths:
        rule = "if "

        for p in path[:-1]:
            if rule != "if ":
                rule += " and "
            rule += str(p)
        rule += " then "
        if class_names is None:
            rule += "response: "+str(np.round(path[-1][0][0][0],3))
        else:
            classes = path[-1][0][0]
            l = np.argmax(classes)
            rule += f"class: {class_names[l]} (proba: {np.round(100.0*classes[l]/np.sum(classes),2)}%)"
        rule += f" | based on {path[-1][1]:,} samples"
        rules += [rule]

    return rules

# Print rules
rules = get_rules(ct, X_train.columns, None)
for r in rules:
    print(r)

